{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c455423-ff75-4bd1-9b49-6e9826440c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export ONNX model for onnxruntime\n",
    "!python deploy/ONNX/export_onnx.py \\\n",
    "    --weights weights/yolov6s.pt \\\n",
    "    --end2end --simplify \\\n",
    "    --topk-all 100 \\\n",
    "    --iou-thres 0.65 \\\n",
    "    --conf-thres 0.35 \\\n",
    "    --img-size 640 640 \\\n",
    "    --dynamic-batch \\\n",
    "    --ort \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4c01e-dac9-417e-b4cf-7c6440e274e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9a121-40a2-4eb6-8a79-94894a01915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "w = \"../../weights/yolov6s.onnx\"\n",
    "imgList = [cv2.imread('../../data/images/image1.jpg'),\n",
    "           cv2.imread('../../data/images/image2.jpg'),\n",
    "           cv2.imread('../../data/images/image3.jpg')]\n",
    "imgList*=7\n",
    "imgList = imgList[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a7721-c49d-4713-94c6-4a57790acabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "session = ort.InferenceSession(w, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1c66b-37bf-4c94-9005-2338331cf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8215aa-918e-4c5a-b67b-70b5c3f1ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114)):\n",
    "    \"\"\"\n",
    "    Preprocess image. For details, see:    \n",
    "    https://github.com/meituan/YOLOv6/issues/613\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "    im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce7a13-31b8-4a35-bd8d-4f0debd46480",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_RGB = []\n",
    "resize_data = []\n",
    "for img in imgList:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    origin_RGB.append(img)\n",
    "    image = img.copy()\n",
    "    image, ratio, dwdh = letterbox(image)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = np.ascontiguousarray(image)\n",
    "    im = image.astype(np.float32)\n",
    "    resize_data.append((im,ratio,dwdh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cae709-f145-4c63-b846-8edd6716f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_batch = np.concatenate([data[0] for data in resize_data])\n",
    "np_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382a4d2-b37a-40be-9618-653419319fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = [i.name for i in session.get_outputs()]\n",
    "outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b448209b-3b92-4a48-9a55-134590e717d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inname = [i.name for i in session.get_inputs()]\n",
    "inname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bc01f-a7c6-47e0-93ed-42f41f631fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 1 infer\n",
    "im = np.ascontiguousarray(np_batch[0:1,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0376a85-ec36-41d3-9067-ec5a8ec5a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 4 infer\n",
    "im = np.ascontiguousarray(np_batch[0:4,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a50aee-fa52-4b6e-aa92-bbb1f12d5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch 5 infer\n",
    "im = np.ascontiguousarray(np_batch[0:5,...]/255)\n",
    "out = session.run(outname,{'images':im})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72d2fd-14dd-42cf-b807-3e8a82b971d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch 32 infer\n",
    "im = np.ascontiguousarray(np_batch/255)\n",
    "out = session.run(outname,{'images':im})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca9301-ba52-4a8c-9ae0-55b28be8a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(out[0].shape[0]):\n",
    "    obj_num = out[0][i]\n",
    "    boxes = out[1][i]\n",
    "    scores = out[2][i]\n",
    "    cls_id = out[3][i]\n",
    "    image = origin_RGB[i]\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    ratio, dwdh = resize_data[i][1:]\n",
    "    for num in range(obj_num[0]):\n",
    "        box = boxes[num]\n",
    "        score = round(float(scores[num]),3)\n",
    "        obj_name = names[int(cls_id[num])]\n",
    "        box -= np.array(dwdh*2)\n",
    "        box /= ratio\n",
    "        box = box.round().astype(np.int32).tolist()\n",
    "        x1 = max(0, box[0])\n",
    "        y1 = max(0, box[1])\n",
    "        x2 = min(img_w, box[2])\n",
    "        y2 = min(img_h, box[3])\n",
    "        color = colors[obj_name]\n",
    "        obj_name += ' '+str(score)\n",
    "        cv2.rectangle(image,(x1, y1),(x2, y2),color,2)\n",
    "        cv2.putText(image,obj_name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ce6a4-4fd9-4804-9afa-e8e8a3e20b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(origin_RGB[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ed2df-ceb8-46c8-8bfc-aa7ff3750f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(origin_RGB[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4449198-3c2b-41d6-9a23-de7accf73d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(origin_RGB[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf6e6e-afb5-4c97-82c3-aeffdc9aba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(origin_RGB[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27485468-2e69-4aaf-8089-ba0134a1b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(origin_RGB[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dad466-7aa2-4ba4-81f1-0d8f57268081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('logo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9307137f18f51d83e37da8476b4fe217ad2ef2bb155f10da85402ed3b56d86d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
